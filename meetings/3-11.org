* Discussion points
** Why do model search?
- The posterior probability of a parameter can be concentrated around 0
- The joint posterior distribution of all parameters could model the uncertainty about which edges to include
- ... But it's not nice with convex likelihoods/priors because it cannot assign high/low probabilities to dis-par combinations of parameters
*** Discussion
- Not prior probability that the parameter is not in the model
- Ratio prior/posterior
** BDGraph approach
- You said :: Pencer et al (finis) ~ pseudo-likelihood that allows to analytically define the Marginal likelihood
- Specific conjugate prior that allows for an approximation of ratio of normalization constants
- The bottleneck was the normalization constants of the inverse-gamma's
*** Discussion
- Impact of priors on the BF
  - Then the assumptions for simplifications have a big effect
- Maybe use different priors during search than during testing
** Using likelihood ratios
- Using LR as estimates of evidence
  - ~upper bound of the posterior
- If we assign the same prior probability to all models
- *And* we use the same priors for the parameters of the models and they are iid
  - But I assume the joint priors don't work this way once we specify them with different dimensions
*** Discussion
- BF is the posterior expectation of the LR
  - If nested models
** Prior information in which prior
- We can incorporate prior information in the prior distribution over parameters
- Or on the prior distribution over models
- How do they interact?
- Does it make sense to penalize complexity with the priors or let just the model search algorithm deal with it?
*** Discussion
- Makes sense to have priors with high probability to sparse and dense models, but not in the middle
- Some are analytical
* Steps
** Contributions to the Julia ecosystem
- I think it's a good idea for me to build a small portfolio of open source stuff during the thesis
*** Interface for Bayesian model averaging
- Implement generic algorithm
- Includes the logic for averaging over a set of models
- Julia is amazing
  - Doesn't take more than writing only the specific case for Occam's window
*** Interface for Occam's window model search
- With an interface agnostic with respect to selection criteria
  - BIC, posterior ratios, likelihood ratios, RNGs
- Julia is amazing
*** Maybe decouple the interface for generic model search
- And Occam's window as a specific case
- Julia is amazing
- Not on the proposal
*** Graphical models interface
- Basic GGM estimation
  - Copy whatever BGGM does
    - What does it do?
      - Matrix-F prior distribution
      - Analytical or sampled (?)
- There are a few packages about Ising models
  - Not in the common modeling interface
  - Focused on simulations rather than the statistical estimation
  - Node-wise for Ising
    - At least so we can evaluate likelihoods 
- Julia is amazing
** Occam's window implementation as a specific case
*** Data structures
  - Instead of sets, vectors of Booleans
    - Ordered
  - The space of possible models is far larger than the space of possible predictors
  - Easy & fast to identify submodels
    - AND & Sum
      - All operations are map-reduceable/transduceable
  - If it's necessary we could use caches for submodels
    - Probably not necessary
  - Definitely cache the selection criteria (BIC / Posterior probabilities / Marginals / Whatever)
  - (BAS uses the same representation for models)
*** Case
- First :: BIC approximation
- Other possibles :: model-dependent
  - Laplace
  - Analytical/Conjugate
  - Analytical/Conjugate with non-analytical regularization constants
  - Ideally something that can be done sequentially and re-use 
** Models
- Linear / logistic as proofs of concept
  - Logistic is not analytical
- GGM easy but analytical
- Ising
** Benchmark 
*** Across multiple models
*** Between approximations / calculations of the marginal likelihoods
*** Against alternatives
- Focus on whether the approach does work/no
**** BAS
- Still needs analytical marginals
- Only implemented for GLMs
**** BDGraph seems to be the state of the art
- .. or not
** Thoughts
- The literature on/using Occam's window is not large
  - Same authors: Raftery & Madigan
- Multiple steps of variable depth
  - We can adjust how many / how deep
- Priorities
  1. BMA & general Occam's algorithm working in Julia
  2. Simulations with linear/logistic regression + BIC
  3. Simulations with linear/logistic regression + analytic solution
     - Should be easy (?)
     - Are conjugate / other analytical priors for these GLMs nice or do most people do MCMC with /better/ priors?
  4. GGM working in Julia
  5. Simulations with GGM + BIC
  6. Explore alternatives to approximate the posterior ratios
  7. ISING
- For the proposal
  - I think that up to point 4. everything is pretty straightforward
  - So probably 4 + choose an approximation
    - Only for GGM
    - I think Mohammadi's (2017) approximation is the best bet, ratio of Gamma functions

* For next week
- First draft of the full proposal
  - And then 2 weeks until deadline
  - Nice amount of time for buffer + feedback + peer reviews

* Data collection
* Use the different priors stuff
* Re-read laplace stuff
- His proffered
- Iterative Laplace or approximation Pensar prios

* GGM marginal 
- From GGM

* Friday 11:00
