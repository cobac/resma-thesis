#+title: Form 2A - Research Master's Psychology: Thesis Research Proposal
#+date:
#+author: 

#+BEGIN_SRC elisp :eval :results none :exports results
  (coba-define-org-tex-template)
  (setq custom-tex-template (mapconcat 'identity (list
                                                  org-tex-report-template
                                                  org-tex-math-template
                                                  org-tex-graphix-template                                                  
                                                  ) "\n"))
(coba-define-org-tex-template)
#+END_SRC

#+LATEX_CLASS_OPTIONS: [12pt]
#+LATEX_HEADER: \setlength{\parskip}{\baselineskip}%
#+LATEX_HEADER: \setlength{\parindent}{4pt}

#+LATEX_HEADER: \defbibheading{bibliography}[7. References]{%
#+LATEX_HEADER: \section*{#1}}

#+LATEX_HEADER: \usepackage{fancyhdr}
#+LATEX_HEADER: \setlength{\headsep}{2.25\parskip}

#+LATEX_HEADER: \usepackage{fancyhdr}
#+LATEX_HEADER: \pagestyle{fancy}
#+LATEX_HEADER: \fancyhf{}
#+LATEX_HEADER: \renewcommand{\headrulewidth}{0pt}
# #+LATEX_HEADER: \setlength\headheight{80.0pt}
# #+LATEX_HEADER: \addtolength{\textheight}{-80.0pt}
#+LATEX_HEADER: \lhead{\includegraphics[width = .40 \textwidth]{uvalogo.pdf}}
#+LATEX_HEADER: \rhead{Graduate School of Psychology}

\thispagestyle{fancy}

\raggedright
* 1. General Information
** 1.1 Student information 
- Student name: :: David Coba
- Student Id card number: :: 12439665
- Address: :: -
- Postal code and residence: :: -
- Telephone number: :: -
- Email address: :: coba@cobac.eu
- Major: :: Psychological methods
  \newpage
** 1.2 Supervisor information
- Supervisor name: :: Maarten Marsman
- Second assesor name: :: Jonas Haslbeck
- Specialization: :: Psychological Methods
** 1.3 Other information
- Date: :: 1.04.2022
- Status: :: First draft
- Number of ECs for the thesis: :: 32EC
- Ethics Review Board (ERB) code: :: -
  
* 2. Title and Summary of the Research Project
** 2.1 Title: Assessing the performance Occam's window for Bayesian model averaging
** 2.2 Summary of proposal 

When we select a statistical model and use it to make inferences about its parameters, we usually ignore the uncertainty derived from the model selection process. There are techniques that address this issue, like Bayesian model averaging. However, it is not evident how to choose the set of candidate models to consider. This is specially the case in contexts where the space of possible models is vast, such as with graphical models. There are multiple model search algorithms used under a Bayesian framework, one of them being Occam's window.

The goal of this project is to assess in general terms if Occam's window is a suitable method to explore the model space, specifically in the context of graphical models. To this end we will conduct a simulation study exploring how the algorithm performs under different conditions and how it compares to other alternative model search techniques.

Keywords: Bayesian inference, model selection, model search algorithms, Occam's window


\hfill Word count: 146/150

* 3. Project description 
# (1200 w)
# Describe prior research, a comprehensible literature review of the research field, converging upon the  research questions. 
# a) Describe the state of affairs, including the theoretical framework, in the current research field based on the existing body of literature.
# b) Clarify how the previous research eventuates into the research questions of the current proposal.

** 3.1 Prior research

# Rewrite the opening
When we perform statistical inferences, such as hypotheses tests about the inclusion of a parameter in a model or whether a parameter lays within an interval, we typically select a statistical model and then use that model to perform the inference.
However, this approach underestimates the total uncertainty in our inferences, since it essentially ignores the uncertainty derived from the model selection process and produces overconfident conclusions \parencites{leamer1978specification}{draper1987modeluncertainty}{hoeting1999bma}[for a recent review of the issue see][]{kaplan2021quantification}.

There are different approaches under a Bayesian framework that allow to model the uncertainty of the model selection process, and address the issue of using a single model for our statistical inferences. These approaches can be categorized into two groups.
The first group is using mixture models that encompass all possible models. To estimate the joint posterior distribution of all possible models researchers usually employ samplers like Markov chain Monte Carlo model composition \parencite[MC^3,][]{madigan1995mc3}, which is based on reversible jump Markov chain Monte Carlo [[parencite:&green1995rjmcmc]].
However, these samplers are hard to implement, are computationally demanding and tend to have instability issues; which is why the second group of methods is generally preferred [[parencite:&yao2018bayesianstacking]].
The second group of approaches to multiple model inference is to combine the information of a set of candidate models \(\mathcal A\). With these methods, the final inference \(p(\Delta | D)\) is the weighted average of that inference across all candidate models \(p(\Delta|M_k, D)\) shown in Equation ref:eq:combination. This approach allows to separate the use of multiple models into two steps: identifying a set of candidate models \(\mathcal A\) and combining the uncertainty from those models.

\begin{equation}
\label{eq:combination}
p(\Delta | D) = \sum_{\forall k : M_k \in \mathcal A}^{} p(\Delta| \mathcal{M}_k, D) w_k
\end{equation}

#   - Relevance for current issues with graphical models
There are two main methods to combine multiple models and not ignore the uncertainty of the model-selection process. The first method is Bayesian model averaging
[[parencite:BMA, &leamer1978specification;&hinne2020modelaveraging;&hoeting1999bma;]]
and uses the posterior probability of candidate models as the model weights of Equation ref:eq:combination. This posterior probability \[
p(M _k | D) = \frac{p(D | \mathcal  M_k) p(M_k)}{\sum_{\forall l : M_l \in \mathcal A}^{} p(D| M_l) p(M_l)} \]
depends on the marginal likelihood of the data under each model\[
p(D | M_k) = \int_{}^{} p(D | \theta_k, M_k) p(\theta_k | M_k) d\theta_k
\]
and their prior probability \(p(M_k)\).
To calculate the marginal likelihoods we need to integrate the product of the likelihood function of each model \(p(D | \theta_k, M_k)\) and the prior distribution of the model parameters \(p(\theta_k | M_k)\) over the whole parameter space. In most cases it is not possible to calculate the marginal likelihoods analytically, and we require of approximate solutions. At the end of this section we provide an overview of the most common approximations.

The second method is model stacking, which minimizes the leave-one-out cross-validation (LOOCV) estimate of a loss function to assign weights to different models [[parencite:&wolpert1992stacking]].
Stacking is a common technique to aggregate point estimations from different models, but [[textcite:&yao2018bayesianstacking]] extend the method to combine Bayesian predictive distributions, producing combined uncertainty distributions similarly to BMA. It is possible to calculate LOOCV estimates from samples of the posterior distribution [[parencite:&vehtari2016loocv]], which makes it convenient if one is using methods such as Markov chain Monte Carlo to estimate the posterior distributions in the first place.

The main difference between BMA and model stacking is their asymptotic behavior when the data-generating model is not in the set of candidate models \(\mathcal A\).
In this scenario, BMA will select the single model that minimizes the Kullback-Leibler divergence from the data-generating process, while model stacking will select the mixture of models that minimizes the loss function that was used to find the model weights parencite:&yao2018bayesianstacking.
The literature is divided between proponents of marginal likelihood based methods, such as Bayes factors and BMA, and proponents of methods based on the posterior predictive distributions, such as LOOCV and model stacking. The disagreements seem to be rooted on differences in philosophical positions and scientific goals [[parencite:&gronau2018limloocv;parencite:&gronau2019rejoinderloocv;&lotfi2022bayesmodel;parencite:&vehtari2018limlimloocv]].

# - BFs /untrained/ models vs ppd-based trained models
# - In this case our ultimate scientific goals are about the conditional dependencies structures in the data, inclusion/exclusion which edges
# - BMA more sensible to the models that are considered than stacking
# - No-one believs that a GGM or an ISING model are the data generating process
#   - maybe maarten irt idk
# - We are going to make trade-offs during the model search phase between computational feasibility and exactness
# - Stacking more robust option for model combination (?)
#   - Although posterior distribution of parameters might be wonky, we were planing on using the sum of weights (posterior model probabilities in BMA) of the models that include a particular parameter

# Rewrite this.. specially the second half of the paragraph
When we do not have strong theoretical arguments to pre-select a set of candidate models \(\mathcal A\), we can use a model search algorithm. One possible algorithm is Occam's window
parencite:&madigan1994occamsgraphical;&raftery1997bmalinear,
which is based on Occam's razor principle.
Occam's razor (also known as the law of parsimony) states than when one is presented with competing hypotheses that explain equally well a particular phenomena, one should choose the simplest one.
In general terms, Occam's window algorithm first selects a set of models that fit the data reasonably well, and then discards all models that have simpler counterparts that fit the data equally well. Formally, the first step equals constructing the set of models\[
\mathcal A' = \left \{ M_k : \frac{\max \{p(M_{l} | D)\}}{p(M _k | D)} \leq c\right  \}
\]
with posterior probabilities \(p(M_k | D)\) not significantly lower 
than the model with highest posterior probability of all models \(M_l \in \mathcal A '\). The constant \(c\) specifies the range of posterior probabilities---the size of the window---that fit the data reasonably well.
For second step the algorithm identifies the set of models \[
\mathcal B = \left\{ M_k : \exists M_l \in \mathcal A',
 M_l \subset M_k,
\frac{p(M_l | D)}{p(M_k | D)} > 1
 \right\} 
 \]
that have at least one submodel \(M_l\) in \(\mathcal A'\) with greater posterior probability.
The final set of candidate models is \(\mathcal A = \mathcal A' \setminus \mathcal B\).
Computationally, the algorithm is a deterministic greedy search that performs two passes over the model space. The first pass goes from the bottom to the top (i.e. comparing the simplest models with \(p\) parameters to models with \(p+1\) parameters and so on), and the second pass starts from the most complex models and compares all the way to the simplest.
To calculate posterior model probabilities \(p(M_k|D)\) we need to compute the marginal likelihood \(p(D|M_k)\) of each model, similarly to BMA. 

One of the drawbacks of Occam's window is that it overestimates the posterior probability of the selected "best" candidate models and it underestimates ---essentially nullifies---the posterior probability of the rest of the models. This is by design and acknowledged by [[textcite:&madigan1994occamsgraphical]], and it is a trade-off we have to make to avoid having to combine information from the complete model space. Occam's window is implemented for linear regression models using priors that allow to analytically calculate the marginal likelihoods [[parencite:&raftery1997bmalinear]] in the R package BMA [[parencite:&raftery2015bma]].
There is also an extension of Occam's window to allows to model streams of data that become available sequentially [[parencite:&onorante2016dynamicow]].

# Occam's window algorithm can take advantage of sequential computations
# particularly efficient when it is possible to reuse the calculations of the marginal likelihood of a model to calculate the marginal likelihood of a model that encompasses the first. 
# [[textcite:&madigan1994occamsgraphical]] describe a procedure that allows to re-use calculations for some graphical models and [[textcite:&raftery1997bmalinear]] for linear models. The latter is implemented in the R package BMA [[parencite:&raftery2015bma]]. 

Alternative model search algorithms include Bayesian adaptive sampling (BAS) and birth-death Markov chain Monte Carlo (BDMCMC). BAS samples without replacement from the space of possible models and uses the marginal likelihoods of the sampled models to iteratively estimate the marginal likelihoods of the models that remain unsampled [[parencite:&clyde2011bas]]. BAS is available for (generalized) linear  models as an R package [[parencite:&clyde2021bas]]. BDMCMC [[parencite:&mohammadi2015bdgraph]] samples from the joint posterior space of all possible models, and uses a Poisson process to model the rate at which the Markov chains jump from one model to another. BDMCMC is available in the R package BDGraph [[parencite:&mohamamadi2019bdgraph]] for graphical models, which uses a pseudo-likelihood funciton [[parencite:&pensar2017marginalpseudo]] and an analytical approximation to the ratio of marginal likelihoods [[parencite:&mohammadi2017accelarating]].

Finally, we also want to give an overview of possible ways of approximating the marginal likelihoods that are required for BMA and Occam's window.
The first and crudest one is to use the Bayesian information criterion \parencite[BIC,][]{schwarz1978bic} as an approximation.
The BIC of a model \(M_k\) is defined as \[
\text{BIC}(M_k) = -2 \log p\left(D | \widehat \theta, M_k \right) + d_{M_k} \log n \text{,}
\] 
where \( p\left(D | \widehat \theta, M_k\right) \) is the likelihood of the maximum likelihood estimate for the parameter values under that model, \(d_{Mi}\) is the number of parameters of the model and \(n\) is the sample size. The logarithm of the marginal likelihood of a model can be approximated as \[
\log p \left( D | M_k \right) \approx
\log p\left(D | \widehat \theta, M_k\right)
-\frac{1}{2} d_{M_k} \log n
\] 
if we assume an unit information prior, which means that \[
\log p \left( D | M_k \right) \approx \frac{\text{BIC}(M_k)}{-2}
\] and that the ratio of marginal likelihoods---the Bayes factor---between two models is \[
2 \log B_i_j = - \text{BIC}(M_i) + \text{BIC}(M_j) \text{.}
\]
Another method to approximate the marginal likelihood is to use bridge sampling [[parencite:&gronau2017bridge;&bennett1976bridge]]. Bridge sampling generally provides accurate approximations of the marginal likelihoods, but is also very computationally demanding since it has to draw samples.
A method between BIC and bridge sampling in terms of accuracy and computational demands is the Laplace approximation [[parencite:&lecam1953some;&kass1995bayesfactors]]. This method approximates the posterior distribution with a normal distribution centered around the posterior mode, which can be estimated using expectation-maximization algorithms. The standard Laplace approximation is accurate to the second moment of the posterior distribution, but it is possible to extend it get more accurate approximations at the cost of more computational resources or further assumptions [[parencite:&ruli2016improvedlaplace;&rue2009inla;&hubin2016inla;&tierney1989laplace;&tierney1986accurate]].
Lastly, note that in the context of Occam's window, it is possible to use a faster but less accurate approximation during model search, and use a slower but more accurate approximation during the model combination step.

# - Occam's window algorithm shines computationally if there is a way of re-using computations and update marginals sequentially

** 3.2 Key questions
# Now state the key questions, the essence of the proposal. Here, the intended research should be connected to prior research. Testable research model/ expectations/ hypotheses should be derived from the key question, and the relation between theory and research hypotheses should be clearly specified.
# a) Formulate a general relevant research question based on previous research.
# b) Translate the general research question in a clear manner into a specific research question.
# c) Translate the specific research questions into testable research model/ expectations/ hypotheses.

The main goal of this project is to assess how Occam's window model search algorithm performs in general terms. To our knowledge there are no simulation studies evaluating its performance under different conditions. We want to explore the possible trade-offs between accuracy and computational speed of different marginal likelihood approximations, and also how it compares to alternative model search algorithms. Specifically, we are motivated by the issue of deciding whether to include or not particular edges in graphical models. The number of possible graphical models grows exponentially with the number of variables, and we want to check if it is feasible to use Occam's window in this context or not.

\hfill Word count: 1449/1200

* 4. Procedure 
# (1000 w)

** 4.1 Operationalization
# Describe how the research questions are operationalized. 
# a) Operationalize the research questions in a clear manner into a research design/strategy. 
# b) Describe the procedures for conducting the research and collecting the data. 
# c) For methodological and/or simulation projects describe the design of the simulation study. 

To address our research questions we will first implement Occam's window model search algorithm and then conduct a simulation study. We plan on implementing our algorithm and running our simulations in the Julia programming language [[parencite:&Julia]].

There are more simulation conditions that are potentially interesting than how many we can realistically tackle during this project, and the number of conditions that we can test will depend on how smoothly the project progresses.
In general terms we plan on running simulations under the following conditions.
First, regarding which models to use during our simulations,
linear regression is the obvious simplest choice to start developing the algorithm. Logistic regression is a next step that increases the complexity of the procedure, and the Gaussian graphical model and the Ising model are the ones that motivate this project. Regarding the choice of model search algorithm we will only implement Occam's window algorithm, and rely on the implementations of BAS [[parencite:&clyde2021bas]] for linear models and BDgraph [[parencite:&mohamamadi2019bdgraph]] for graphical models as benchmarks. Also, since Occam's window algorithm uses marginal likelihoods during model search, it is most practical to use BMA to combine the candidate models, which is also how the algorithm was originally conceived. We will not use model stacking during our simulations. Next, regarding the choice of approximations of the marginal likelihood, we will start with the BIC since it is the simplest approximation and it will allow us to test our implementation of Occam's window while developing it. We will also implement Laplace approximations since we predict that these approximations will be the most efficient in terms of the trade-off between computational speed and accuracy. We will have to explore which specific implementation of the Laplace approximation is more appropriate for our goals.
Lastly, we will also consider different sample sizes and sparsity levels in the covariance matrices of the data-generating models. Taking this into consideration, these are broadly speaking the conditions we will prioritize testing:

1. Occam's window with linear regression models and BIC approximation.
2. Occam's window with linear regression models and Laplace approximation.
3. Occam's window with logistic regression models and Laplace approximation.
4. Occam's window with Gaussian graphical models and BIC approximation.
5. Occam's window with Gaussian graphical models and Laplace approximation.
6. BAS with its current implementation in R.
7. BDgraph with its current implementation in R.
8. Occam's window with Ising models and BIC approximation.
9. Occam's window with Ising models and Laplace approximation.
10. Using Occam's window model search with BIC, re-run BMA but using the Laplace approximation.
11. Using Occam's window model search with BIC, re-run BMA but using bridge sampling.

We believe that it is realistic to complete up to condition no. 9 in this project. Evaluating the performance of conditions no. 10 and no. 11 will most likely remain open questions for future research.

** 4.2 Sample characteristics
# d) In case of a simulation study, indicate how data will be generated

We plan on generating data from a set of models and evaluate how well each simulation condition recovers the characteristics of the true data-generating models.
However, we do not think it makes sense to commit to specific data-generating processes at this stage of the project.
   
** 4.4 Data analysis
 # Describe the data preprocessing. Indicate for each research question separately, how it is translated into a statistical prediction. For example: “In a repeated measures ANOVA we expect an interaction effect of the between factor x and the within factor y on the dependent variable z. Also indicate how you will correct for multiple comparisons. Only the analyses proposed here can be described as confirmatory analyses in your research report. All other have to be mentioned as exploratory. 

This project is inherently exploratory and, similarly to the last section, we do not think it makes sense to commit at this stage to a specific analysis plan. In general terms, to assess how well each model-search algorithm performs we will compare the posterior probabilities of the true data-generating model, and the posterior probabilities of including specific edges that are present on the data-generating model.
To assess computational costs we will use real runtime in order to not penalize algorithms that benefit from parallel computations. If instead we used CPU time, we would be penalizing all parallelizable algorithms by a factor of the number of parallel processes or threads.

** 4.4 Modifiability of procedure
# Is there room for modification of the intended procedure? Evaluation of the proposal by the RMP Thesis Committee is meaningful only if the recommendations that the Committee might have can be implemented. It is therefore required that the intended procedure can be modified before you start gathering data. In situations where procedures or operationalization’s or sample characteristics cannot be modified, the Thesis Committee has to be consulted before handing in the research proposal. The committee will consider the eligibility of this project for a research thesis. 

In section 4.1 we have ordered some possible simulation conditions in order of priority and we have estimated how many are realistic to complete during this thesis project. If our estimations prove to be overconfident, we can choose to exclude additional conditions, starting with the ones with lowest priority. Similarly, if everything goes smoother than planned, we can choose to simulate and analyze additional conditions.
 
\hfill Word count: 703/1000

* 5. Intended results 
# (250 w)
# Clarify what the implication of possible outcomes would be (per hypothesis) for the specific and general research questions as well as for the theory. Address the following in approximately 250 
# words:
# a) What are the interpretations if the results do  match the expectations? 
# b) What are the interpretations if the results do not match the expectations?
# c) Are there any alternative interpretations?
# d) Is there any practical or societal relevance? Please explain. 

The main goal of this project is to assess in general terms how Occam's window performs. 
If our analysis concludes that the algorithm compares favorably against alternative methods, we will show that Occam's window can be a useful tool to supplement the use of BMA to avoid the problem of single model inference.
We are motivated specially by the case of graphical models, where the space of possible models grows exponentially with the number of variables. 
Current approaches to sampling from the complete model space have limitations, and we anticipate that Occam's window can be a useful tool that is currently underused.
In case that our results show that the performance of Occam's window does not compensate for its shortcomings, we would have provided an updated assessment of its performance that is currently lacking in the literature.
Moreover, we expect to contribute software that implements BMA and Occam's window, and that integrates with the rest of the Julia ecosystem. 

\hfill Word count: 163/250

* 6. Work plan
# (500w)
# Describe how the research project will be executed. Who is doing what and when? Is the planning of the current project realistic, efficient and feasible?
** 6.1 Time schedule
# State the total amount of EC as noted in the thesis contract (26-32EC excl. proposal), 1EC stands for 28 hours work. Present and justify a time schedule in weeks, including your time investment in hours per week. Plan some spare time, and indicate what elements can be cut / reduced if necessary. Provide the intended presentation date.

This thesis project consists of 28 EC, excluding the thesis proposal. This is equivalent to approximately 18 weeks working full time. We aim to complete and present the project by the 15th of July 2022. In broad terms we plan to achieve the following milestones each month:

- April :: 
  - Week 1/2: Address feedback on the proposal and implement Occam's window algorithm for linear regression models using BIC as an approximation to the marginal likelihood.
  - Week 3: Implement the Laplace approximation to the marginal likelihood and test its performance with linear regression models.
  - Week 4: Implement the Laplace approximation for logistic models and buffer time.
- May :: 
  - Week 1: Buffer time and hopefully enjoy the UvA teaching-free days.
  - Week 2: Implement the Laplace approximation for graphical Gausian models and start running simulations.
  - Week 3: Buffer time and start running simulations with BAS and BDGraph.
  - Week 4: Continue running simulations and buffer time.
- June :: 
  - Week 1: Implement the Laplace approximation for Ising models.  Continue running simulations. 
  - Week 2: Continue running simulations and start analyzing results. Start writing the thesis.
  - Week 3/4: Analyze results and thesis writing. Complete a first draft of the full thesis.
- July :: 
  - Weeks 1/2: Complete writing the thesis and prepare the presentation.

As detailed in section 4.4 "Modifiability of procedure", the scope of this project is highly flexible, and we can adapt which conditions to include or exclude in our simulation study depending on how fast we progress.

** 6.2 Infrastructure
# Where will the research take place? How is access to the facilities and materials ensured?

No special infrastructure is required to complete this project.
** 6.3 Data storage
# Each researcher needs to comply with the storage protocol of the Research Institute Psychology: http://psyres.uva.nl/content/scientific-integrity-docs/data-protocol.html 

We will keep the results of all our simulations under version control and with remote backups. We do not plan on collecting any data, and in the case we end up deciding to use empirical data we would use publicly available datasets.

** 6.3 Budget
# The compensation from the department is max € 55 for each research project. If the total expenditure exceeds the maximum compensation, then specify how the surplus will be financed. The budget may be used for travel expenses, participant payment. Specify the financial ramifications for the intended research. Another € 25 budget may be used for printing costs (e.g. for the conference poster). Please go to the secretariat of the specialization of your supervisor with your receipts. 

In principle we will not require extra funds to complete this project. In the case that the computational resources that we have access to prove insufficient to conduct the simulations, we might consider using cloud computing services. In any case, such costs would not exceed the maximum budget.

\hfill Word count: 333/500

\printbibliography

* 8. Further steps
Make sure your supervisor submits an Ethics Checklist for your intended research to the Ethics Review Board of the Department of Psychology at https://www.lab.uva.nl/lab/ethics/
* 7. Signatures
- [ ] I hereby declare that both this proposal, and its resulting thesis, will only contain original material and is free of plagiarism (cf. Teaching and Examination Regulation in the research master’s course catalogue).
- [ ] I hereby declare that the result section of the thesis will consist of two subsections, one entitled “confirmatory analyses” and one entitled “exploratory analyses” (one of the two subsections may be empty):
  1. The confirmatory analysis section reports exactly the analyses proposed in Section 4 of this proposal.
  2. The exploratory analysis section contains not previously specified, and thus exploratory, proposal analyses. 
  
\centering
*Location:* \hspace{1cm} *Student’s signature:* \hspace{1cm} *Supervisor’s signature:*

\raggedright
\hspace{1.5cm} Amsterdam
