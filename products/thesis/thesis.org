#+BEGIN_SRC elisp :eval :results none :exports results
	
	(coba-define-org-tex-template)
	(setq custom-tex-template (mapconcat 'identity (list
																									org-tex-apa-template
																									org-tex-math-template
																									org-tex-graphix-template																									
																									) "\n"))
(coba-define-org-tex-template)
#+END_SRC

#+LATEX_HEADER: \setlength{\parskip}{\baselineskip}%
#+LATEX_HEADER: \setlength{\parindent}{4pt}
#+LATEX_HEADER: \usepackage{algorithm}
#+LATEX_HEADER: \usepackage[noend]{algorithmic}

#+LATEX_HEADER: \title{\textbf{Research Master's Thesis\\
#+LATEX_HEADER:	 Occam's window and Bayesian model averaging for graphical models}}
#+LATEX_HEADER: \author{David Coba \\ St. no. 12439665} 
#+LATEX_HEADER: \course{Psychological Methods}
#+LATEX_HEADER: \affiliation{Research Master's Psychology \\ University of Amsterdam}
#+LATEX_HEADER: \professor{ \hphantom{1cm} \\ % 
#+LATEX_HEADER: Supervised by: \\% 
#+LATEX_HEADER: \hspace{.65cm} Maarten Marsman
#+LATEX_HEADER: \hphantom{1cm} }
#+LATEX_HEADER: \duedate{Some day of August, 2022}

#+LATEX_HEADER: \abstract{
#+LATEX_HEADER: When we select a statistical model and use it to make inferences about its parameters, we usually ignore the uncertainty derived from the model selection process, leading to overconfident inferences. There are techniques that address this, like Bayesian model averaging (BMA). However, when the space of possible models is vast, such as with graphical models that are popular in psychology, it is not evident how to efficiently find the most relevant models to average over with BMA. Occam's window is a model search algorithm that explores the space of possible models, and it is designed to generate a set of candidate models for BMA.
#+LATEX_HEADER:
#+LATEX_HEADER: The goal of this project was to assess in broad terms if Occam's window is a suitable method to explore the model space, specifically in the context of graphical models. To this end we developed an Occam's window implementation, and conducted a simulation study exploring how the algorithm performs under different conditions and how it compared to other alternative model search techniques. Our results show that in its current form, our algorithm underperforms compared to the alternatives. We discuss potential avenues for improving its performance, but it is not clear whether it might be worth to develop it further.
#+LATEX_HEADER: }

#+LATEX_HEADER: \keywords{Bayesian inference, Bayesian model averaging, model selection, Occam's window, Gaussian graphical model}

#+LATEX_HEADER: \shorttitle{Occam's Window}

\thispagestyle{empty}

\maketitle

* Introduction
# (1200 w)
# Describe prior research, a comprehensible literature review of the research field, converging upon the research questions.
# - Describe the state of affairs, including the theoretical framework, in the current research field based on the existing body of literature.
# - Clarify how the previous research eventuates into the research questions of the current proposal

When we perform statistical inferences, such as hypotheses tests about the inclusion of a parameter in a model or whether a parameter lays within an interval, we typically select a statistical model and then use that model to perform the inference.
However, this single-model approach underestimates the total uncertainty in our inferences, since it ignores the uncertainty derived from the model selection process. And, ignoring this uncertainty, leads to overconfident conclusions \parencites{leamer1978specification}{draper1987modeluncertainty}{hoeting1999bma}[for a recent review of the issue see][]{kaplan2021quantification}.
The aim of this project in general terms was explore whether an algorithm called Occam's window can be useful to deal with the issue of single-model inference.
We wanted to know whether it can produce results that are good enough to be used, while also being able to run in an adequate time frame.
To his end, we have developed an implementation of Occam's window that can work with any statistical model and we have conducted a preliminary simulation study to benchmark its performance.
Specifically, we were motivated by the issue of deciding whether to include or not particular edges in graphical models that are popular in psychology. The number of possible graphical models grows exponentially with the number of variables, and current approaches to multi-model inference struggle because of the size of the model space.

Different Bayesian solutions have been proposed that allow us to model the uncertainty of the model selection process, which can be categorized into two groups.
The first group is using mixture models that encompass all possible models. To estimate the joint posterior distribution of all possible models researchers usually employ simulation based methods like Markov chain Monte Carlo model composition \parencite[MC^3,][]{madigan1995mc3} or reversible jump Markov chain Monte Carlo [[parencite:&green1995rjmcmc]]. These algorithms explore the joint posterior distribution by drawing samples from the space of all possible parameter values of all possible models.
However, it is often impossible to implement simulation based methods that produce good results in realistic time frames, and they tend to have stability issues
[[parencite:&yao2018bayesianstacking]].
The second group of approaches to multi-model inference is to only combine the information from a set of pre-specified candidate models \(\mathcal A\), instead of using the whole model space. To combine a set of candidate models we can use Bayesian model averaging
[[parencite:BMA, &leamer1978specification;&hinne2020modelaveraging;&hoeting1999bma]]. 
This approach allows to separate the use of multiple models into two steps: first identifying a set of candidate models \(\mathcal A\) and then combining the uncertainty from those models.
With BMA, the posterior probability of our target inference (\(\Delta\), e.g. whether a parameter is included in the model or not) given the observed data, \(p(\Delta | D)\), is the weighted average of that inference across all candidate models \(p(\Delta |M_k, D), \; M_k \in \mathcal A\). 
BMA uses the posterior probability of candidate models \(p(M_k | D)\) as model weights, and our target inference \(p(\Delta | D)\) becomes 
\begin{equation*}
\label{eq:bma}
p(\Delta | D) = \sum_{\forall M_k \in \mathcal A} p(\Delta| \mathcal{M}_k, D) p(M_k | D)
 \text{.}
\end{equation*}
For example, the posterior probability that a specific parameter is included in a model becomes the sum of the posterior probabilities of all models that include that parameter.

From Bayes theorem we know that the posterior probability of a model is the product of the prior probability of that model \(p(M_k)\) times the marginal likelihood of the data under that model \(p(D|M_k)\), divided by the total probability of the data \(p(D)\).
Moreover, the total probability of the data \(p(D)\) is the weighted sum of the marginal probability of the data under each model (the likelihood of the data, \(p(D|M_k)\)), using the prior probability of each model \(p(M_k)\) as weights.
The full expression for the posterior probability of a model becomes:
 \[
p(M _k | D) = \frac{p(D |	M_k) p(M_k)}{\sum_{\forall M_l \in \mathcal A}^{} p(D| M_l) p(M_l)} \text{.}\] Note, that if we assume a uniform prior across the model space, the posterior model probabilities become proportional to their marginal likelihoods.
And, to calculate the marginal likelihoods we need to integrate the product of the likelihood function of each model \(p(D | \theta_k, M_k)\) and the prior distribution of the model parameters \(p(\theta_k | M_k)\) over the whole parameter space of that model:
\[
p(D | M_k) = \int_{}^{} p(D | \theta_k, M_k) p(\theta_k | M_k) d\theta_k \text{.}
\]
This is often not possible to do analytically, but there are multiple ways of approximating the marginal likelihood of different models. We will expand more about this in a latter section.

Ideally, we would like to use domain knowledge and theoretical arguments to specify the set of candidate models \(\mathcal A\) to average with BMA.
However, when that is not realistic, we can use model search algorithms instead, to avoid having to consider the whole model space.
One possible algorithm is the topic of this thesis: Occam's window, which was introduced by textcite:&madigan1994occamsgraphical and is based on Occam's razor principle.

** Occam's window as a concept

Occam's razor---also known as the law of parsimony---states that when one is presented with competing hypotheses that explain equally well a particular phenomena, one should choose the simplest one.
In general terms, Occam's window approach first selects a set of models that fit the data reasonably well, and then discards from that set all models that have simpler counterparts that fit the data equally well. The final result is the set of simplest models that explain the data well enough, and that set of models is the set of candidate models \(\mathcal A\) that is considered during BMA.
# If the algortihm was exhaustive it would be the Pareto frontier.

Formally, the first step equals constructing the set of models\[
\mathcal A' = \left \{ M_k : \log	 \frac{\max \left[p(M_{l} | D)\right]}{p(M _k | D)} \leq O_L\right	\}
\]
with posterior probabilities \(p(M_k | D)\) not significantly lower 
than that of the model with highest posterior probability \(M_l \in \mathcal A '\). The constant \(O_L\) specifies the range of posterior probabilities that are acceptable, the size of the window of models that fit well enough. Under the special case when \(O_L = 1\), \(\mathcal A '\) would only include the single model with greatest posterior probability.
For the second step, the algorithm identifies a set of models to discard from \(\mathcal A'\): \[
\mathcal B = \left\{ M_k : \exists M_l \in \mathcal A',
 M_l \subset M_k,
\log \frac{p(M_l | D)}{p(M_k | D)}	> O_R
 \right\} 
 \]
that have at least one submodel \(M_l\) in \(\mathcal A'\) with significantly greater posterior probability, and the range of acceptable differences is controlled by the constant \(O_R\). 
Under the special case when \(O_R = 1\), \(\mathcal B\) would include all models that have a simpler submodel with higher posterior probability, which implies that in the final set of candidate models there would not be any model that is a submodel of  other included model.
The final set of candidate models is the set of models in the first set that are not present in the second \(\mathcal A = \mathcal A' \setminus \mathcal B\). That is, the set of models that fit the data reasonably well and that do not have simpler counterparts that fit the data well enough.

Both constants, \(O_L\) and \(O_R\), determine the size of the window---hence the name of the algorithm---of acceptable posterior probabilities to consider, depicted in Figure ref:fig:window. For any pair of models \(M\) and \(M_0\), where \(M_0\) is a submodel of \(M\), we would expect the set of candidate models \(\mathcal A\) to include either of them, or both of them, depending on the ratio of their posterior probabilities.
When the ratio of posterior probabilities lies inside the window, both \(M\) and \(M_0\) are included in \(\mathcal A\).

\begin{figure}[H]
	\centering
	\caption{The ``window'' from Occam's window, which width is determined by the constants
		\(O_L\) and \(O_R\). \(M_0\) is a submodel of \(M\).
	Figure adapted from \textcite{madigan1994occamsgraphical}.}
	\label{fig:window}
	\includegraphics[width=\linewidth]{figures/window.pdf}
\end{figure}

However, if we were to translate the formal definition that I have described in this section into a practical algorithm, we would quickly run into issues. Even though the idea behind Occam's window is to avoid having to consider the whole model space for BMA, applying the formal definition literally step-by-step would mean that we have to explore the whole model space anyway. In the next section I will go over two different algorithms that implement Occam's window in a practical way.


** Occam's window algorithms

The first algorithm (Algorithm ref:algo:occams) is described in [[textcite:&madigan1994occamsgraphical]], and it is a deterministic greedy search over the model space. The algorithm starts from a set of initial candidate models \(\mathcal C\), and performs two passes iteratively deleting (in the first pass) or adding (in the second pass) parameters. In their examples they initialize \(\mathcal C\) with a single saturated model that includes all possible parameters. They showcase the algorithm with Gaussian graphical models (GGM), where they propose an analytical computation of the marginal likelihood that allows to re-use computations across models, which is ideal for model search algorithms. However, their approach is restricted to chordal graphical structures and they do not report results about its performance, since they only show applied empirical examples and not simulations results.

# To calculate posterior model probabilities \(p(M_k|D)\) we need to compute the marginal likelihood \(p(D|M_k)\) of each model, similarly to BMA. 
# However, in most cases it is not possible to calculate marginal likelihoods analytically, and we require of approximate solutions. 

\begin{algorithm}[H]
	\caption{Occam's window algorithm from \textcite{madigan1994occamsgraphical}.
		An immediate submodel \(M_0\) or supermodel \(M_1\) means that the models differ from the original model \(M\) by a single parameter.}
	\label{algo:occams}

	\begin{algorithmic}[1]
		\REQUIRE $\mathcal C$
		\STATE $\mathcal A \leftarrow \emptyset$
		\REPEAT[Down pass]
		\STATE Select a model $M$ from $\mathcal C$.
		\STATE $\mathcal C \leftarrow \mathcal C \setminus \left\{ M \right\}; \;\; \mathcal A \leftarrow \mathcal A \cup \left\{ M \right\}$ 
		\FOR{inmediate submodel $M_0$ of $M$}
		\STATE Compute $B = \log \left[ p \left( M_0|D \right) / p(M | D)	 \right]$
		\IF{$B > O_R$}
		\STATE $\mathcal A \leftarrow \mathcal A \setminus \left\{ M \right\}$ 
		\IF{$M_0 \notin \mathcal C$}
		\STATE $\mathcal C \leftarrow \mathcal C \cup \left\{ M_0 \right\}$ 
		\ENDIF
		\ELSIF{$O_L \leq B \leq O_R$}
		\IF{$M_0 \notin \mathcal C$}
		\STATE $\mathcal C \leftarrow \mathcal C \cup \left\{ M \right\}$
		\ENDIF
		\ENDIF
		\ENDFOR
		\UNTIL{$\mathcal C$ is empty.}

		\STATE $\mathcal C \leftarrow \mathcal A; \;\;	\mathcal A \leftarrow \emptyset$
		
		\REPEAT[Up pass]
		\STATE Select a model $M$ from $\mathcal C$.
		\STATE $\mathcal C \leftarrow \mathcal C \setminus \left\{ M \right\}; \;\; \mathcal A \leftarrow \mathcal A \cup \left\{ M \right\}$ 
		\FOR{inmediate supermodel $M_1$ of $M$}
		\STATE Compute $B = \log \left[ p \left( M|D \right) / p(M_1 | D)	 \right]$
		\IF{$B < O_L$}
		\STATE $\mathcal A \leftarrow \mathcal A \setminus \left\{ M \right\}$ 
		\IF{$M_1 \notin \mathcal C$}
		\STATE $\mathcal C \leftarrow \mathcal C \cup \left\{ M_1 \right\}$ 
		\ENDIF
		\ELSIF{$O_L \leq B \leq O_R$}
		\IF{$M_1 \notin \mathcal C$}
		\STATE $\mathcal C \leftarrow \mathcal C \cup \left\{ M_1 \right\}$
		\ENDIF
		\ENDIF
		\ENDFOR
		\UNTIL{$\mathcal C$ is empty.}

		\RETURN $\mathcal A$
		\end{algorithmic}

\end{algorithm}

The second algorithm \parencites{raftery1995bms}{raftery1997bmalinear}, Algorithm ref:algo:bma, is implemented for linear, logistic and multinomial-logit regression models in the R packages BMA and mlogitBMA parencite:&raftery2015bma, and is a significant deviation from the original approach. This version treats the set of initial candidate models \(\mathcal C\) as a proxy of the whole model space, and does not fit new submodels or supermodels during the model search.
Therefore, we have to use another method to generate \(\mathcal C\), and then the algorithm eliminates models from that set. The R package BMA uses a leaps-and-bounds algorithm [[parencite:&furnival1974leaps]] to generate \(\mathcal C\). The leaps-and-bounds is extremely performant in the linear regression case (less than six floating point operations per model), because it re-uses most calculations across models.
 
	\begin{algorithm}[H]
		\caption{Occam's window as implemented in BMA. An immediate submodel \(M_0\) means that the model differ from the original model \(M\) by a single parameter.}
		\label{algo:bma}
		\begin{algorithmic}[1]
			\REQUIRE $\mathcal C$
			\FOR{$M | M \in \mathcal C$}
				\STATE Compute $B_{max} = \log \frac{ \displaystyle\left\{ \max \left[	 p \left( M_l|D \right) | \forall M_l \in \mathcal C \right] }{ \displaystyle p(M | D)	\right\}}$
				\IF{$B_{max} > O_L$}
					\STATE $\mathcal C \leftarrow \mathcal C \setminus \left\{ M \right\}$
				\ELSE
					\FOR{inmediate submodel $M_0$ of $M$	$| M_0 \in \mathcal C$}
						\STATE Compute $B = \log \left[ p \left( M_0|D \right) / p(M | D)	 \right]$
						\IF{$B > O_R$}
							\STATE $\mathcal C \leftarrow \mathcal C \setminus \left\{ M \right\}$ 
						\ELSIF{$B < O_L$}
							\STATE $\mathcal C \leftarrow \mathcal C \setminus \left\{ M_0 \right\}$
						\ENDIF
					\ENDFOR
			 \ENDIF
			\ENDFOR 
			\RETURN $\mathcal A \leftarrow \mathcal C$

		\end{algorithmic}

	\end{algorithm}

Lastly, there is a third algorithm,
an extension of Occam's window that allows to perform BMA on streams of data that become available sequentially [[parencite:&onorante2016dynamicow]], but dealing with streams of data is not relevant for our goals, so we have not considered this algorithm in this project.

** Marginal likelihood approximations

Since Occam's window uses marginal likelihoods to compare models many times during the model search, we need efficient ways of approximating them.
The first and crudest approximation is to use the Bayesian information criterion \parencites[BIC,][]{schwarz1978bic}{kass1995bayesfactors}.
The BIC of a model \(M_k\) is defined as \[
\text{BIC}(M_k) = -2 \log p\left(D | \widehat \theta, M_k \right) + d_{M_k} \log n \text{,}
\] 
where \( p\left(D | \widehat \theta, M_k\right) \) is the likelihood 
function evaluated at the maximum likelihood estimates of the model's parameters,
\(d_{M_k}\) is the number of parameters in the model and \(n\) is the sample size. textcite:&kass1995bayesfactors show that the logarithm of the marginal likelihood of a model can be approximated as \[
\log p \left( D | M_k \right) \approx
\log p\left(D | \widehat \theta, M_k\right)
-\frac{1}{2} d_{M_k} \log n \text{,}
\] 
which means that \[
\log p \left( D | M_k \right) \approx \frac{\text{BIC}(M_k)}{-2}
\] and that the ratio of marginal likelihoods between two models---the Bayes factor---is \[
2 \log B_i_j = - \text{BIC}(M_i) + \text{BIC}(M_j) \text{.}
\]
This is the approach used by the BMA R package [[parencite:&raftery2015bma]].
Bridge sampling offers another approach to approximate the marginal likelihood [[parencite:&gronau2017bridge;&bennett1976bridge]]. Bridge sampling generally provides accurate approximations of marginal likelihoods, but is also computationally demanding and not usable with a model search algorithm that has to calculate (at least) thousands of marginal likelihoods. This is the case because it is a simulation based method that works drawing samples from the posterior distribution of the parameters of each model, and it requires a high number of samples to accurately estimate the marginal likelihood.
A method between BIC and bridge sampling in terms of accuracy and computational demands is the Laplace approximation [[parencite:&lecam1953some;&kass1995bayesfactors]]. This method approximates the posterior distribution with a normal distribution centered around the posterior mode, which can be estimated using expectation-maximization algorithms. The standard Laplace approximation is accurate to the second moment of the posterior distribution, but it is possible to extend it to get more accurate approximations at the cost of more computational resources or further assumptions [[parencite:&ruli2016improvedlaplace;&rue2009inla;&hubin2016inla;&tierney1989laplace;&tierney1986accurate]].
Lastly, for some models, depending on the prior choices there are analytical solutions of the marginal likelihood.
Also, note that in the context of Occam's window and BMA, it is possible to use a faster but less accurate approximation during model search, and use a slower but more accurate approximation during the BMA step.

In practice, instead of using posterior probabilities, Occam's window implementations assume an uniform prior across the model space and use the marginal likelihood as a proxy for the posterior model probability. Comparisons based on Bayes factors already penalize models of higher complexity that have similar predictive performance [[parencite:&kass1995bayesfactors]], but it is also possible to implement different model priors without much computational cost.

# - Occam's window algorithm shines computationally if there is a way of re-using computations and update marginals sequentially

** Alternative approaches

Under a Bayesian framework, the most common alternative model search algorithm designed to be used for BMA of (generalized) linear models is Bayesian adaptive sampling \parencite[BAS,][]{clyde2011bas}, which samples without replacement from the space of possible models and uses the marginal likelihoods of the sampled models to iteratively estimate the marginal likelihoods of the models that remain unsampled. BAS is available as an R package [[parencite:&clyde2021bas]]. 

For GGMs, there are no implementations available of a model search algorithm designed to be used for BMA. However, there are other model search approaches. One of them is birth-death Markov chain Monte Carlo (BDMCMC), which samples from the joint posterior space of all possible models, and uses a Poisson process to model the rate at which the Markov chains jump from one model to another [[parencite:&mohammadi2015bdgraph;&mohammadi2017accelarating]]. BDMCMC is available in the R package BDGraph parencite:&mohamamadi2019bdgraph for graphical models.
Another popular approach is to use Bayes Factors to test whether to include or not specific parameters in a model
parencite:&williams2020bggmtest, which is implemented in the R package BGGM [[parencite:&williams2020bggm]]. However, this approach is not attempting to explore the model space, but doing pair-wise hypothesis tests for every parameter.

# Intented results: 


# The goals of this project are to develop an efficient Occam's window implementation for graphical models that are popular in psychological research, like the Gaussian graphical model (GGM) and the Ising model, and benchmark its performance.


# The main goal of this project is to assess in general terms how Occam's window performs.
# The main limitation of current methods in the context of graphical models, like BDMCMC from BDGraph, is that they are prohibitively slow.
# We anticipate that Occam's window will produce results faster, and we think that it can be a useful tool that is currently underused.
# If our analysis concludes that the results Occam's window are good enough in terms of sensitivity and specificity, while also being significantly faster than the alternatives, we will show that the algorithm can be a useful tool to supplement the use of BMA to avoid the problem of single-model inference. 
# In case that our results show that the performance of Occam's window does not compensate for its shortcomings, we would have provided an updated assessment of its performance that is currently lacking in the literature.
# To our knowledge there are no simulation studies evaluating how Occam's window performs under different conditions, or how it compares to other model search algorithms.
# 
# Moreover, we expect to contribute software that implements BMA and Occam's window, and that integrates with the rest of the Julia ecosystem. 
* Our Occam's window implementation

During my thesis I have implemented a general version of Occam's window, based on Algorithm ref:algo:occams, in the Julia programming language parencite:&Julia. Because of Julia's multiple dispatch system, it is possible to use the program with any marginal likelihood approximation and with any statistical model. The only requirements are that the model parameters can be represented as a vector of bits, and that the user defines a function to calculate the marginal likelihood of a model. The way the program is designed allows to easily cache results, and to implement sequential calculations that re-use the computations from one model to the next. Moreover, because of Julia's virtually-zero-cost abstractions, the program can be almost as performant as an implementation in a traditionally compiled language, as long as the marginal likelihood computation is defined in an efficient way. By default the program supports linear regression models and GGMs, both using the BIC approximation to the marginal likelihood. To obtain the maximum likelihood estimates of linear regression models we use Cholesky-decomposed ordinary least squares, and estimation-maximization as implemented in the R package /psychonetrics/ for the GGMs. Therefore, the current implementation does not reuse computations across models, although it caches results from previously explored models.
# CANCELED: Cite psychonetrics... no citation

The program also allows to specify different sets of initial candidate models \(\mathcal C\). The current implementation allows starting from a single saturated model that includes all parameters, a single random model or multiple random models. Additionally, for linear regression models, it also supports the leaps-and-bounds algorithm parencite:&furnival1974leaps to generate a set of starting candidate models.

* Simulation study 
The goal of the simulation study was to assess in broad terms whether	 Occam's window is a potentially usable approach to Bayesian variable selection in the context of GGMs. In this section I will describe the procedure we have used and the results we have obtained. However, the current implementation is not the most optimal possible, there is room for improvement and there are multiple modifications that could improve its performance. I will elaborate on the limitations of this study and about potential modifications in the discussion section.

** Procedure 
# (1000 w)
# ** Operationalization
# - Operationalize the research questions in a clear manner into a research design/strategy. 
# - Describe the procedures for conducting the research and collecting the data. 
# - *For methodological and/or simulation projects describe the design of the simulation study.*

*** Data generation
The simulation study is divided in two parts, simulations for linear regression models and for GGMs.

We used a 4-way design for the linear regression simulations with 3x3x3x6 conditions. The possible number of total variables were \( \left\{5, 10, 20	 \right\} \), the number of observations per variable \( \left\{ 10, 20, 100 \right\}\) and the proportion of the total variables used in the data-generating models \(\left\{ 1/4, 1/2, 1 \right\}\). If we ended up with a fractional number we rounded it to the lowest integer. For example, if the number of total variables in the simulated data set was \(10\) and the proportion of total variables was \(1/4\), the true data-generating model used 2 variables.
For each simulation condition, we generated data drawing predictor samples from a normal distribution with \(\mu = 0\)	and \(\sigma = 1\), drawing regression parameters from a normal distribution with \(\mu = 0\)	 and \(\sigma = 10\), and adding normal noise to the dependent variables with \(\mu = 0\)	 and \(\sigma = 1\). 

For each simulated dataset, we used the R package BAS, the R package BMA and our Occam's window implementation. The R package BMA uses default values \(O_R = \log(20)\) and \(O_L = 1\) during Occam's window, but we noticed during the development of our implementation that sometimes we would obtain better results with both constants being one. This implies that the /window/ of Occam's window collapses and that the algorithm becomes a simple greedy search that just selects the model with higher posterior probability at every comparison. To assess this, we did run our implementation with both sets of constants. Additionally, the R package BMA uses leaps-and-bounds to generate a model set that they use as a proxy of the whole model space, and we also wanted to compare how using this set of initial candidate models \(\mathcal C\) impacts Algorithm ref:algo:occams performance versus using a single saturated model as recommended by [[textcite:&madigan1994occamsgraphical]].
In total, this leaves us with 6 different model specifications, which are depicted in Table ref:table:models.
We ran each condition 20 times.

We also used a 4-way design for the GGM simulations, in this case with
2x2x2x3 conditions. The total number of possible variables were \(
\left\{ 5, 10 \right\}\), sample sizes of \( \left\{ 500, 2000
\right\}\), and \( \left\{0.25, 0.75 \right\}\) as the proportion of
sparsity in the data-generating networks---the proportion of omitted
edges. To generate positive definite precision matrices we used the
procedure followed by
[[textcites:&epskamp2017generalized;&yin2011genomicsggm]]. First, we
generate a network structure without weights, just choosing which
edges include or not at random. Next, we draw weights from a uniform
distribution between 0.5 and 1, and we make them negative half of the
time. Then, we set the diagonal elements of the precision matrix to
1.5 times the sum of the absolute values of each row. Finally, we
divide each element by the diagonal value of the corresponding row and
average the upper and lower triangular matrices to assure that the
precision matrix is symmetric. This creates partial correlation 
networks in which the non-zero edges have a mean of 0.33 and a
standard deviation of 0.04. For each simulated dataset, we used the R package BGGM /explore()/ function with its default values, the R package BDgraph, also with its default values, and our Occam's window implementation with \(O_R = \log(20)\) and \(O_L = 1\), as shown in Table ref:table:models. We ran each condition 15 times.

#+CAPTION: Models used in the simulation study.
#+NAME: table:models
|				 <c>				|							 <c>							 |			 <c>			 |					<c>					 |
|				Model				|						Algorithm						 | \(\mathcal C\)	 |	 \(O_R\) & \(O_L\)	 |
|-------------------+--------------------------------+-----------------+-----------------------|
| Linear regression |																 |								 |											 |
|-------------------+--------------------------------+-----------------+-----------------------|
|				 BAS				|							 BAS							 |				-				 |					 -					 |
|				 BMA				|	 Occam's window ref:algo:bma	 | Leaps & bounds	 | \(\log(20)\) & \(1\)	 |
|				Ours				| Occam's window ref:algo:occams | Leaps & bounds	 | \(\log(20)\) & \(1\)	 |
|					"					|								"								 |				"				 |		 \(1\) & \(1\)		 |
|					"					|								"								 | Saturated model | \(\log(20)\) & \(1\)	 |
|					"					|								"								 |				"				 |	 \(1\)		 & \(1\)	 |
|-------------------+--------------------------------+-----------------+-----------------------|
|				 GGM				|																 |								 |											 |
|-------------------+--------------------------------+-----------------+-----------------------|
|				BGGM				|					 Pairwise BF					 |				-				 |					 -					 |
|			 BDgraph			|							BDMCMC						 |				-				 |					 -					 |
|				Ours				| Occam's window ref:algo:occams | Saturated model | \(\log(20)\)	 & \(1\) |

The number of simulations per condition is constrained by the available computational resources. All simulations were run in a laptop with an Intel i7-7700HQ CPU processor under less-than-ideal thermal conditions.

*** Analysis

All models, except BGGM, return the posterior probability of a
parameter being present or not in the data-generating model. BGGM
returns instead the Bayes factor of a model with that parameter
included against a similar model without that parameter. Having those
values, and knowing the true parameters included in the data
generating models, we can use a decision threshold (e.g. posterior
probability greater than 0.5 or Bayes factor greater than 3) to
calculate the sensitivity (i.e. proportion of true positives) and
specificity (i.e. proportion of true negatives) of each algorithm. Our
plan was to plot sensitivity versus specificity curves using multiple
thresholds, and calculate the area under those curves as an indicator
of performance. However, the output from all algorithms was very
bimodal, with the posterior probabilities of different parameters
being very close to 0 or very close to 1---or very close to 0 or in
the \(10^{ 10 }\) order of magnitude for the Bayes factors reported by
BGGM. Therefore, we have chosen to use a simple decision threshold
(posterior probability of 0.5 or Bayes factor of 3) to calculate the
sensitivity and specificity of each algorithm.

We also planned on reporting the average time per run of each algorithm as a measure of computational speed. However, there are two issues with this metric.
First, the laptop used to run the simulations experienced significant thermal throttling in some cases.
Second, because of computational constrains 
we had to set a time limit to our implementation of Occam's window with GGMs.
If a single run of the algorithm would still be running after 1 hour, it wold be a timeout, and the program would return the current set of accepted models \(\mathcal A\). We kept track of which runs timed-out, and we indented to present their results separated from those of runs that executed in less than 1 hour. However, when a simulation timed out, all simulations of the same condition ended up timing-out as well. We mark in the results sections which conditions produced time-outs.
Therefore, because of these two limitations any comparison across the algorithms' runtime would be unfair. However, their runtime are in different orders of magnitude altogether, so a rough approximation of their runtime should not be less informative that an accurate one.

** Results

The bar plots of every simulation condition represent the sensitivity (top bar) and specificity (bottom bar) of each algorithm. If both sides of a bar are full it means that the algorithm performed very well under those conditions, and the shorter they are, the worse it performed.

Figure ref:fig:linear shows the results for the linear regression simulations. We can see that both BMA and BAS performed very well, since they achieved sensitivities and specificities of (almost) 1 under every condition. This was also the case for our implementation of Occam's window when we set both constants to 1 and Occam's window /collapses/ into a simple greedy step-wise search. On the other hand, our Occam's window implementation achieved very poor results under most conditions when used as intended (i.e. with the constants specifying a window of accepted models).
Lastly, note that all algorithms identified correctly when the true data-generating model was the saturated model, as shown in the last column of Figure ref:fig:linear. In this case, all algorithms had a sensitivity of 1, and a specificity of 0, since there were no true missing edges.
Our implementation performed better when the total number of variables considered by the algorithm was highest, when using a /good/ set of initial candidate models (i.e. the one generated by the leaps-and-bounds algorithm), and, predictably, when the sample sizes were greater.

In terms of running time, both BAS and BMA outperformed our implementation. BAS executed typically in less than 2 seconds; BMA in a fraction of a second, often less than 100 milliseconds; and our implementation run for a few seconds, usually less than 5.

\begin{figure}[H]
	\caption{Simulation results of the linear regression models. The top of each bar is the sensitivity and the bottom the specificity of each algorithm.}
	\label{fig:linear}
	\centering
	\includesvg[width=15.5cm]{../../sims/figures/linear_results.svg}
\end{figure}

In figure ref:fig:ggm we can see the results from the graphical models simulations. In conditions with high sparsity both BDgraph and BGGM performed very well, while our implementation tended to include parameters that were not present in the data-generating models. However, in conditions of lower sparsity all algorithms had low specificity and the differences in performance were less pronounced, although our implementation was still outperformed by the alternatives. 

On the other hand, when considering execution time, the differences across the three algorithms were more pronounced than in the linear regression case. BGGM executed in a fraction of a second and BDgraph in a few seconds, but usually less than 5 seconds. However, our implementation took over 30 minutes for every run, even exceeding 1 hour of runtime and timing-out in half of the simulation conditions, those where the number of variables was 10. 

\begin{figure}[H]
	\caption{Simulation results of the GGMs. The top of each bar is the sensitivity and the bottom the specificity of each algorithm. Bars marked with an asterisk correspond to simulations that timed-out.}
\label{fig:ggm}
	\centering
	\includesvg[height=20cm]{../../sims/figures/ggm_results.svg}
\end{figure}

* Discussion
The goal of this thesis project was to asses whether Occam's window is a potentially useful algorithm to explore the space of possible models, specially in the case of graphical models.
Our results show that, at least for now, our implementation of Occam's window is not capable of matching the performance of alternative algorithms. Neither in terms of accuracy of the results nor in terms of computational speed. Our implementation runs in an acceptable time frame when dealing with linear regression models, but its performance is worse than the alternatives. In the case of GGMs the performance of our implementation was closer to that of the alternatives, albeit still significantly underperforming, but it took a prohibitively amount of time to execute.

The algorithms we have benchmarked our implementation against, BGGM and BDgraph, work very well when dealing with simple cases (i.e. continuous, normally distributed data), but their performance is not as good under more complex conditions. These method are essentially as optimized as they can be, while our implementation is still very bare-bones. In this sense, Occam's window still has the potential of outperforming the alternatives in more complex scenarios. There are two main avenues for improving the performance of our implementation that we think have the most potential. 
The first one, would be to implement a method of calculating the marginal likelihoods that allows to re-use computations across different models, to improve its execution speed. The standard way of obtaining the maximum likelihood estimates required to calculate the BIC in the case of the GGMs is to use estimation-maximization methods, which make it difficult to re-use computations across models. We could instead use pseudolikelihoods functions like those proposed in [[textcite:&pensar2017marginalpseudo]] or [[textcite:&mohammadi2017accelarating]], for which deriving sequential calculations might be possible. 
The second avenue to improve Occam's window performance is to use a method to find a good set of initial candidate models. One of the keys of the excellent performance of the  BMA R package is the quality of the set of initial candidate models generated by the leaps-and-bounds algorithm. In our simulations with GGMs we just used a single saturated model as a starting point, and using a better set of initial models might significantly improve Occam's window performance---although that was not always the case in our linear regression results. If the quality of the initial set was good enough to act as a proxy of the full model space, it would even be an option to use Algorithm ref:algo:bma instead of Algorithm ref:algo:occams.
A potential method of reducing the model space that Occam's window has to explore is the approach proposed by textcite:&marsman2022rbinnbet, which allows to discard edges from the total set of possible edges in graphical models. However, although this approach will limit the space of models to explore, it will not necessarily help in finding a set of good initial candidate models from that reduced model space.

Our results do not show that Occam's window is a very promising method, but they do not show either that it is clearly an impractical algorithm to use with graphical models.
Whether it is worth pursuing the development of an implementation of Occam's window for graphical models is not a question that we can answer in absolute terms. It depends on our personal trade-offs between the perceive importance of the issue of variable selection in graphical models, and the potential increase in performance versus alternative approaches. 

* Materials

All project materials are available in the following GitHub repository: 
https://github.com/cobac/resma-thesis . It includes the code of our Occam's window implementation, code for all simulations and analyses, simulations raw output and intermediary analysis results.

\printbibliography
